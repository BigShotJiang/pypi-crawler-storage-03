{
  "name": "gptqmodel",
  "version": "4.0.0",
  "summary": "Production ready LLM model compression/quantization toolkit with hw accelerated inference support for both cpu/gpu via HF, vLLM, and SGLang.",
  "author": "ModelCloud",
  "license": "Apache 2.0",
  "home_page": "https://github.com/ModelCloud/GPTQModel",
  "download_filename": "gptqmodel-4.0.0.tar.gz",
  "download_time": "2025-08-22T20:23:15.737374",
  "package_url": "https://pypi.org/project/gptqmodel/"
}